---
title: "CS02 - Predicting Annual Air Pollution"
author: "Michael Tang, Vivian Lee, Jennifer Kim, Madeleine Jimenez, and Hsiang-An Pao"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: spacelab
    highlight: tango
    code_folding: show
---

## Introduction

Air pollution is a pressing environmental issue, with various types of pollutants affecting air quality. Among these, fine particulate matter (PM2.5)—particles smaller than 2.5 µm in diameter—is particularly harmful [^1]. Exposure to PM2.5 is linked to severe health problems, and some regions in the United States experience pollution levels that exceed the World Health Organization's recommended limits [^2] [^3]. 

Accurately predicting annual average air pollution concentrations in the U.S. has significant benefits, such as informing public health initiatives and guiding policy decisions. While traditional air pollution measurement methods provide valuable data, their uneven distribution nationwide and limited coverage of PM2.5 levels create gaps in understanding [^4]. To address this problem, we use machine learning to develop a model aimed at improving the accuracy of air pollution predictions. This model also incorporates climate region as a factor to account for geographic variability, seeking to enhance prediction accuracy, especially in regions with sparse monitor coverage.

[^1]: https://www.epa.gov/pm-pollution/particulate-matter-pm-basics
[^2]: https://www.epa.gov/pm-pollution/particulate-matter-pm-basics
[^3]: https://www.stateofglobalair.org/sites/default/files/soga_2019_fact_sheet.pdf
[^4]: https://ehjournal.biomedcentral.com/articles/10.1186/1476-069X-13-63

```{r setup, include=FALSE}
# control global Rmd chunk settings
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Questions

-   With what accuracy can we predict US annual average air pollution concentrations?
-   How does incorporating a climate region category affect the accuracy of PM2.5 concentration predictions?

### Load packages

```{r load-packages, message=FALSE}
library(tidyverse)
library(tidymodels)
library(olsrr)
library(GGally)
```

## The Data

Our data comes from the US Environmental Protection Agency (EPA), the National Aeronautics and Space Administration (NASA), the US Census, and the National Center for Health Statistics (NCHS).

It contains 48 features (variables) with values for each of the 876 monitors (observations).

##### The features are:

-   **id** \| Monitor number
    -   The county number is indicated before the decimal and the monitor number is indicated after the decimal\
    -   Example: 1073.0023 is Jefferson county (1073) and .0023 one of 8 monitors
-   **fips** \| Federal information processing standard number for the county where the monitor is located
    -   5 digit id code for counties (zero is often the first value and sometimes is not shown)
    -   First two numbers indicate the state, last three numbers indicate the county
    -   Example: Alabama’s state code is 01 because it is first alphabetically
    -   Note: Alaska and Hawaii are not included because they are not part of the contiguous US
-   **Lat** \| Latitude of the monitor in degrees
-   **Lon** \| Longitude of the monitor in degrees
-   **state** \| State where the monitor is located
-   **county** \| County where the monitor is located
-   **city** \| City where the monitor is located
-   **CMAQ** \| Estimated values of air pollution from a computational model called [Community Multiscale Air Quality (CMAQ)](https://www.epa.gov/cmaq)
    -   A monitoring system that simulates the physics of the atmosphere using chemistry and weather data to predict the air pollution
    -   Data from EPA
-   **zcta** \| [Zip Code Tabulation Area](https://en.wikipedia.org/wiki/ZIP_Code_Tabulation_Area) where the monitor is located
    -   Postal Zip codes are converted into “generalized areal representations” that are non-overlapping
    -   Data from the 2010 Census
-   **zcta_area** \| Land area of the zip code area in meters squared
    -   Data from the 2010 Census
-   **zcta_pop** \| Population in the zip code area
    -   Data from the 2010 Census
-   **imp_a500, imp_a1000, imp_a5000, imp_a10000, imp_a15000** \| Impervious surface measure
    -   Impervious surface are roads, concrete, parking lots, buildings
    -   Measured within a circle with a radius of 500, 1000, 5000, 10000, and 15000 meters respectively around the monitor
-   **county_area** \| Land area of the county of the monitor in meters squared
-   **county_pop** \| Population of the county of the monitor
-   **Log_dist_to_prisec** \| Log (Natural log) distance to a primary or secondary road from the monitor
    -   Highway or major road
-   **log_pri_5000m, log_pri_10000m, log_pri_15000m, log_pri_25000m** \| Count of primary road length in meters in a circle with a radius of 5000, 10000, 15000, and 25000 meters respectively around the monitor (Natural log)
    -   Highways only
-   **log_prisec_500m, log_prisec_1000m, log_prisec_5000m, log_prisec_10000m, log_prisec_15000m, log_prisec_25000m** \| Count of primary and secondary road length in meters in a circle with a radius of 500, 1000, 5000, 10000, 15000, 25000 meters around the monitor (Natural log)
    -   Highway and secondary roads
-   **log_nei_pm25_10000m, log_nei_pm25_15000m, log_nei_pm25_25000m** \| Tons of emissions from major sources data base (annual data) sum of all sources within a circle with a radius of 10000, 15000, 25000 meters of distance respectively around the monitor (Natural log)
    -   Fine Particulate Matter (diameter 2.5 µm)
-   **log_nei_pm10_10000m, log_nei_pm10_15000m, log_nei_pm10_25000m** \| Tons of emissions from major sources data base (annual data) sum of all sources within a circle with a radius of 10000, 15000, 25000 meters of distance respectively around the monitor (Natural log)
    -   Large Coarse Particulate Matter (diameter 10 µm)
-   **popdens_county** \| Population density (number of people per kilometer squared area of the county)
-   **popdens_zcta** \| Population density (number of people per kilometer squared area of zcta)
-   From the Census:
    -   **no_hs** \| Percentage of people in zcta area where the monitor is that do not have a high school degree
    -   **some_hs** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was some high school education
    -   **hs_grad** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was completing a high school degree
    -   **some_college** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was completing some college education
    -   **associate** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was completing an associate degree
    -   **bachelor** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was a bachelor’s degree
    -   **grad** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was a graduate degree
    -   **poverty** \| Percentage of people in zcta area where the monitor is that lived in [poverty](https://aspe.hhs.gov/2008-hhs-poverty-guidelines) in 2008
-   **hs_or_less** \| Percentage of people in zcta area where the monitor whose highest formal educational attainment was a high school degree or less (sum of no_hs, some_hs, and hs_grad)
-   **urc2013, urc2006** \| [2013](https://www.cdc.gov/nchs/data/series/sr_02/sr02_166.pdf), [2006 Urban-rural classification](https://www.cdc.gov/nchs/data/series/sr_02/sr02_154.pdf) of the county where the monitor is located
    -   6 category variable - 1 is totally urban 6 is completely rural
    -   Data from the [National Center for Health Statistics](https://www.cdc.gov/nchs/index.htm)
-   **aod** \| Aerosol Optical Depth measurement from a NASA satellite
    -   Based on the diffraction of a laser
    -   Used as a proxy of particulate pollution
    -   Unit-less - higher value indicates more pollution
    -   Data from NASA

### Data Import

```{r}
pm <- read_csv("data/pm25_data.csv")
```

### Data Wrangling and EDA

To preface, we renamed certain lengthy variables for ease of viewing and consistency:

```{r}
pm <- pm |>
  rename( 
    
    # Distance to a primary or secondary road (Natural Log)
    log_dist_prisec = log_dist_to_prisec,
    
    # Road lengths (Natural Log) - Primary roads
    log_pri_5000m = log_pri_length_5000,
    log_pri_10000m = log_pri_length_10000,
    log_pri_15000m = log_pri_length_15000,
    log_pri_25000m = log_pri_length_25000,
    
    # Road lengths (Natural Log) - Primary and Secondary roads
    log_prisec_500m = log_prisec_length_500,
    log_prisec_1000m = log_prisec_length_1000,
    log_prisec_5000m = log_prisec_length_5000,
    log_prisec_10000m = log_prisec_length_10000,
    log_prisec_15000m = log_prisec_length_15000,
    log_prisec_25000m = log_prisec_length_25000,
    
    # NEI PM2.5 emission sums (Natural Log)
    log_nei_pm25_10000m = log_nei_2008_pm25_sum_10000,
    log_nei_pm25_15000m = log_nei_2008_pm25_sum_15000,
    log_nei_pm25_25000m = log_nei_2008_pm25_sum_25000,
    
    # NEI PM10 emission sums (Natural Log)
    log_nei_pm10_10000m = log_nei_2008_pm10_sum_10000,
    log_nei_pm10_15000m = log_nei_2008_pm10_sum_15000,
    log_nei_pm10_25000m = log_nei_2008_pm10_sum_25000,
    
    # Education-related variables
    no_hs = nohs,
    some_hs = somehs,
    hs_grad = hs,
    some_college = somecollege,
    
    # Poverty rate
    poverty = pov,
    hs_or_less = hs_orless,
)
```

After importing our data, we added an additional column called `climate_region` that assigns one of nine climate regions based on the state the monitor is located in. These climate regions are defined as "climatically consistent regions within the contiguous United States which are useful for putting current climate anomalies into a historical perspective" by the National Centers for Environmental Information [^5]. 

[^5]: https://www.ncei.noaa.gov/access/monitoring/reference-maps/us-climate-regions

```{r}
climate_regions <- c(
  "Connecticut" = "Northeast",
  "Delaware" = "Northeast",
  "District Of Columbia" = "Northeast",
  "Maine" = "Northeast",
  "Maryland" = "Northeast",
  "Massachusetts" = "Northeast",
  "New Hampshire" = "Northeast",
  "New Jersey" = "Northeast",
  "New York" = "Northeast",
  "Pennsylvania" = "Northeast",
  "Rhode Island" = "Northeast",
  "Vermont" = "Northeast",
  "Iowa" = "Upper Midwest",
  "Michigan" = "Upper Midwest",
  "Minnesota" = "Upper Midwest",
  "Wisconsin" = "Upper Midwest",
  "Illinois" = "Ohio Valley",
  "Indiana" = "Ohio Valley",
  "Kentucky" = "Ohio Valley",
  "Missouri" = "Ohio Valley",
  "Ohio" = "Ohio Valley",
  "Tennessee" = "Ohio Valley",
  "West Virginia" = "Ohio Valley",
  "Alabama" = "Southeast",
  "Florida" = "Southeast",
  "Georgia" = "Southeast",
  "North Carolina" = "Southeast",
  "South Carolina" = "Southeast",
  "Virginia" = "Southeast",
  "Montana" = "Northern Rockies and Plains",
  "Nebraska" = "Northern Rockies and Plains",
  "North Dakota" = "Northern Rockies and Plains",
  "South Dakota" = "Northern Rockies and Plains",
  "Wyoming" = "Northern Rockies and Plains",
  "Arkansas" = "South",
  "Kansas" = "South",
  "Louisiana" = "South",
  "Mississippi" = "South",
  "Oklahoma" = "South",
  "Texas" = "South",
  "Arizona" = "Southwest",
  "Colorado" = "Southwest",
  "New Mexico" = "Southwest",
  "Utah" = "Southwest",
  "Idaho" = "Northwest",
  "Oregon" = "Northwest",
  "Washington" = "Northwest",
  "California" = "West",
  "Nevada" = "West"
)

# Add a new column with region labels
pm_clim <- pm |>
  mutate(climate_region = recode(state, !!!climate_regions))
```

The boxplot below illustrates PM2.5 concentrations across the nine climate regions, showcasing the varying levels of air pollution experienced in each region.

```{r}
pm_clim |>
  ggplot(aes(x = climate_region, y = value, fill = climate_region)) + 
    geom_boxplot() + 
    theme_classic() + 
    labs(title = "Distribution of PM2.5 Concentrations by Climate Region", 
         x = "Climate Region", 
         y = "Value") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "none")
```

To examine the data, we decided to split the monitors into four quadrants according to the latitude and longitude lines that bisect the U.S. and compare CMAQ levels across these new conditions. We found that the northwestern quadrant had much lower CMAQ levels than the other three quadrants.  

```{r}
# Creating a new column based on the quadrant of the US the monitor is in
pm_quad <- pm |>
  mutate(quadrant = case_when(
    lon >= -100 & lat >= 40 ~ "northeast",
    lon >= -100 & lat < 40 ~ "southeast",
    lon < -100 & lat >= 40 ~ "northwest",
    lon < -100 & lat < 40 ~ "southwest"
  ))
pm_quad %>% 
  ggplot(aes(y = CMAQ, x = quadrant)) +
  geom_boxplot() +
  labs(title = "Lowest CMAQ Levels in Northwestern Quadrant",
       x = "Quadrant of the U.S.") +
  theme_minimal() +
  theme(plot.title.position = "plot") 
```


```{r}
pm_dens <- pm |> 
  mutate(id = as.character(id))
```

```{r}
pm_long <- pm_dens |> 
  select(1:2, CMAQ, aod, everything()) |>
  pivot_longer(2:4)
```

```{r} 
plot_popdens_zcta <- {
  pm_long |> 
    ggplot(aes(x = popdens_zcta, y = value)) + 
      geom_point(color = "#19831C") +
      facet_wrap(~name, scales = "free") +
      scale_y_continuous(expand = expansion(mult = c(0, 0.1)), limits = c(0, NA)) +
      theme_classic() +
      labs(title = "Air Pollution Metrics by Zip Code Population Density",
           x = "popdens_zcta") +
      theme(strip.background = element_blank(),
            plot.title.position = "plot")
}
plot_popdens_zcta # Probably delete my plots
```

```{r}
plot_popdens_county <- {
  pm_long |> 
    ggplot(aes(x = popdens_county, y = value)) + 
      geom_point(color = "#88231C") +
      facet_wrap(~name, scales = "free") +
      scale_y_continuous(expand = expansion(mult = c(0, 0.1)), limits = c(0, NA)) +
      theme_classic() +
      labs(title = "Air Pollution Metrics by County Population Density",
           x = "popdens_county") +
      theme(strip.background = element_blank(),
            plot.title.position = "plot")
}
plot_popdens_county
```

```{r}
plot_popdens_zcta <- {
  pm_long |> 
    filter(popdens_zcta <= 5000) |>  # Filter for popdens_zcta <= 5000
    ggplot(aes(x = popdens_zcta, y = value)) + 
      geom_point(color = "#19831C") +
      facet_wrap(~name, scales = "free") +
      scale_y_continuous(expand = expansion(mult = c(0, 0.1)), limits = c(0, NA)) +
      theme_classic() +
      labs(title = "Air Pollution Metrics by Zip Code Population Density",
           x = "popdens_zcta") +
      theme(strip.background = element_blank(),
            plot.title.position = "plot")
}
plot_popdens_zcta
```

```{r}
plot_popdens_county <- {
  pm_long |> 
    filter(popdens_county <= 5000) |>  # Filter for popdens_county <= 5000
    ggplot(aes(x = popdens_county, y = value)) + 
      geom_point(color = "#88231C") +
      facet_wrap(~name, scales = "free") +
      scale_y_continuous(expand = expansion(mult = c(0, 0.1)), limits = c(0, NA)) +
      theme_classic() +
      labs(title = "Air Pollution Metrics by County Population Density",
           x = "popdens_county") +
      theme(strip.background = element_blank(),
            plot.title.position = "plot")
}
plot_popdens_county
```

The following visualizations show PM2.5 levels based on population density, one visualization is divided by both state and population density. From the box plots you can see that high population density has very consistent PM 2.5 levels as there are no outliers and the pink box is very thin while the low population density has a bigger pink box and several outliers. Through the second visualization you can also see how each state's PM2.5 levels differ. 

```{r}
# Maddy's EDA
pm_cl <- pm |> 
  mutate(pop_density_cluster = cut(popdens_county, breaks = 3, labels = c("Low", "Medium", "High")))


ggplot(pm_cl, aes(x = pop_density_cluster, y = value)) +
  geom_boxplot(fill = "pink") +
  labs(title = "PM2.5 Levels by Population Density Clusters",
       x = "Population Density Cluster",
       y = "PM2.5 Levels")


ggplot(pm_cl, aes(x = pop_density_cluster, y = value)) +
  geom_boxplot(fill = "green") + facet_wrap(~state) +
  labs(title = "PM2.5 Levels by Population Density Clusters and State",
       x = "Population Density Cluster",
       y = "PM2.5 Levels")
```

```{r}
#Sean's EDA
#check development correlation
select(pm, contains("imp")) |>
  GGally::ggcorr(hjust = .85, size = 3,
       layout.exp=2, label = TRUE)
#want to compare education vs. development but was negative
pm |>
select(no_hs, popdens_county, 
       hs_grad, imp_a10000, some_college) |>
  GGally::ggpairs()
#population density and emission are correlated
pm |>
select(log_nei_pm25_10000m, popdens_county) |>
  GGally::ggpairs()
```

We brainstormed that another factor that could add another layer of accuracy to predicting air pollution concentrations would be observing whether how urban counties are impact pollution levels. To visualize the potential correlation between urbanicity and emissions, we utilized a correlation matrix plot:  


```{r}
#Correlation Matrix between Urbancity and Log NEI Emissions
select(pm, matches("nei|urc")) |>
  GGally::ggcorr(hjust = .85, size = 3,
                 layout.exp=2, label = TRUE)
```

The shaded blue areas highlight a negative correlation between the urbanicity (urc) and log NEI emissions (log_nei). The negative correlation means that as urbanicity decreases (from urban to rural), emission levels tend to decrease as well. This finding is expected given that urban environments are typically more industrialized, densely populated, and often have higher vehicle traffic—all contributing to elevated pollution levels.


Since there seems to be a correlation between urbanicity and emission levels, we employed sets of boxplots to examine the data more closely. As a reminder, the urbanicity measure spans 6 categorical values with 1 most urban and 6 being rural. 

```{r}
#Reshaped Log NEI Emission and Urbanicity values to long format for easier faceting
pm_long_urc <- pm |>
  pivot_longer(cols = starts_with("log_nei_pm25"), 
               names_to = "log_nei", 
               values_to = "emissions") |>
  pivot_longer(cols = starts_with("urc"), 
               names_to = "urc_year", 
               values_to = "urbanicity")

#Faceted Boxplots for both urbanicity years and emission levels
ggplot(pm_long_urc, aes(x = urbanicity, y = emissions)) +
  geom_boxplot(aes(color = factor(urbanicity))) +
  theme_minimal() +
  labs(x = "Urbanicity", y = "Log NEI Emissions") +
  facet_wrap(~ urc_year + log_nei) +
  theme_minimal()
```

From these boxplots, we observe a clear decrease in average emissions as urbanicity levels decrease (from urban to rural), further reinforcing the idea that urban counties contribute more significantly to pollution.



## Analysis

### Model 1

To create the first model without climate regions as a factor, we used the `pm` dataset. First, `id`, `fips`, and `zcta` were coded as factors, to ensure they were treated as categorical variables in the model.

```{r}
pm <- pm |>
  mutate(across(c(id, fips, zcta), as.factor)) 
```

In addition, we created modified the `city` column, classifying locations as either "In a city" or "Not in a city" based on the original `city` column values.

```{r}
pm <- pm |>
  mutate(city = case_when(city == "Not in a city" ~ "Not in a city",
                          city != "Not in a city" ~ "In a city"))
pm
```

```{r}
set.seed(1234) # same seed as before
pm_split <- rsample::initial_split(data = pm, prop = 0.7)
pm_split
```

We splitted our data into training and testing subsets, with 70% of the data allocated to the training set and the remaining 30% reserved for testing.

```{r}
 train_pm <- rsample::training(pm_split)
 test_pm <- rsample::testing(pm_split)
```

Next, we created a 4-fold cross-validation object from the `train_pm` dataset to divide the training data into four subsets (folds) for cross-validation, enabling model performance evaluation across multiple splits.

```{r}
set.seed(1234)
vfold_pm <- rsample::vfold_cv(data = train_pm, v = 4)
vfold_pm
```

We then defined a preprocessing recipe, `RF_rec`, to prepare the `train_pm` dataset for training a Random Forest model by cleaning and optimizing the features.

- assigning roles:
  - `everything()`, i.e., all variables are first assigned the role of "predictor" for model input variables.
  - `value` was reassigned as the response/outcome variable
  - `id` was reassigned as the "id variable" to uniquely identify observations
  - "fips" was reassigned with the role of "county id."

- we used `step_novel("state")` to prepare the model to handle any unseen levels in the state variable during cross validation

- we converted categorical columns into factors, dropped the unnecessary categorical features, and removed variables that are highly correlated or have near-zero variance


```{r}
RF_rec <- recipe(train_pm) |>
    update_role(everything(), new_role = "predictor")|>
    update_role(value, new_role = "outcome")|>
    update_role(id, new_role = "id variable") |>
    update_role("fips", new_role = "county id") |>
    step_novel("state") |>
    step_string2factor("state", "county", "city") |>
    step_rm("county") |>
    step_rm("zcta") |>
    step_corr(all_numeric())|>
    step_nzv(all_numeric())
```

We used a workflow to combine the preprocessing recipe and the predictive model steps for streamlined modeling.

```{r}
RF_PM_model <- parsnip::rand_forest(mtry = 10, min_n = 3) |> 
  set_engine("randomForest") |>
  set_mode("regression")

RF_PM_model
```

```{r}
RF_wflow <- workflows::workflow() |>
  workflows::add_recipe(RF_rec) |>
  workflows::add_model(RF_PM_model)

RF_wflow
```

We fit the `RF_wflow` workflow to the training dataset, `train_pm`.

```{r}
RF_wflow_fit <- parsnip::fit(RF_wflow, data = train_pm)

RF_wflow_fit
```

We generated a variable importance plot for the fitted Random Forest model. 

```{r}
RF_wflow_fit |> 
  extract_fit_parsnip() |> 
  vip::vip(num_features = 10)
```

We performed cross-validation and collects the performance metrics for the `RF_wflow` workflow using the `vfold_pm` cross-validation object

```{r}
set.seed(456)
resample_RF_fit <- tune::fit_resamples(RF_wflow, vfold_pm)
collect_metrics(resample_RF_fit)
```

We defined a `rand_forest` model with hyperparameters that will be tuned.

```{r}
tune_RF_model <- rand_forest(mtry = tune(), min_n = tune()) |>
  set_engine("randomForest") |>
  set_mode("regression")
    
tune_RF_model
```

We defined a workflow, `RF_tune_wflow`, that combines the preprocessing recipe and the tunable Random Forest model.

```{r}
RF_tune_wflow <- workflows::workflow() |>
  workflows::add_recipe(RF_rec) |>
  workflows::add_model(tune_RF_model)

RF_tune_wflow
```

```{r}
n_cores <- parallel::detectCores()
n_cores
```

We performed hyperparameter tuning for the Random Forest model within the `RF_tune_wflow` workflow using grid search. It evaluates the model using the vfold_pm cross-validation object (which contains 4 folds) and tests a grid of 20 different combinations of hyperparameters.

```{r}
doParallel::registerDoParallel(cores = n_cores)

set.seed(123)
tune_RF_results <- tune_grid(object = RF_tune_wflow, resamples = vfold_pm, grid = 20)
tune_RF_results
```

We collected the performance metrics from the hyperparameter tuning process stored in `tune_RF_results`.

```{r}
tune_RF_results |>
  collect_metrics()
```

```{r}
show_best(tune_RF_results, metric = "rmse", n = 1)
```

We selected the best hyperparameter combination based on the root mean square error (RMSE) from the results of the hyperparameter tuning process.

```{r}
tuned_RF_values <- select_best(tune_RF_results,  metric = "rmse")
tuned_RF_values
```

We finalized the Random Forest workflow by applying the best hyperparameters identified through grid search. The model was then trained and evaluated on both the training and test datasets using the last_fit() function. Finally, performance metrics such as R^2 and RMSE are collected.

```{r}
# specify best combination from tune in workflow
RF_tuned_wflow <-RF_tune_wflow |>
  tune::finalize_workflow(tuned_RF_values)

# fit model with those parameters on train AND test
overallfit <- RF_wflow |>
  tune::last_fit(pm_split)

collect_metrics(overallfit)
```

```{r}
test_predictions <- collect_predictions(overallfit)
test_predictions
```

### Model 2

To create the second model that includes climate regions as a factor, we used the `pm_clim` dataset. We followed the same steps, except for some changes that are noted.

```{r}
pm_clim <- pm_clim |>
  mutate(across(c(id, fips, zcta), as.factor)) 
```

```{r}
pm_clim <- pm_clim |>
  mutate(city = case_when(city == "Not in a city" ~ "Not in a city",
                          city != "Not in a city" ~ "In a city"))
pm_clim
```

```{r}
set.seed(1234) # same seed as before
pm_split <- rsample::initial_split(data = pm_clim, prop = 0.7)
pm_split
```

```{r}
 train_pm <- rsample::training(pm_split)
 test_pm <- rsample::testing(pm_split)
```

A 5-fold cross-validation object is created from the `train_pm` dataset to divide the training data into five subsets for cross-validation. Increasing v to 5 enabled higher test accuracy on the final model.

```{r}
set.seed(1234)
vfold_pm <- rsample::vfold_cv(data = train_pm, v = 5)
vfold_pm
```

When creating the recipe, we ensured `climate_region` was included as a factor.

```{r}
RF_rec <- recipe(train_pm) |>
    update_role(everything(), new_role = "predictor")|>
    update_role(value, new_role = "outcome")|>
    update_role(id, new_role = "id variable") |>
    update_role("fips", new_role = "county id") |>
    step_novel("state") |>
    step_string2factor("state", "county", "city", "climate_region") |>
    step_rm("county") |>
    step_rm("zcta") |>
    step_corr(all_numeric())|>
    step_nzv(all_numeric())
```

```{r}
RF_PM_model <- parsnip::rand_forest(mtry = 10, min_n = 3) |> 
  set_engine("randomForest") |>
  set_mode("regression")

RF_PM_model
```

```{r}
RF_wflow <- workflows::workflow() |>
  workflows::add_recipe(RF_rec) |>
  workflows::add_model(RF_PM_model)

RF_wflow
```

```{r}
RF_wflow_fit <- parsnip::fit(RF_wflow, data = train_pm)

RF_wflow_fit
```

```{r}
RF_wflow_fit |> 
  extract_fit_parsnip() |> 
  vip::vip(num_features = 10)
```

```{r}
set.seed(456)
resample_RF_fit <- tune::fit_resamples(RF_wflow, vfold_pm)
collect_metrics(resample_RF_fit)
```

We now see a slightly improved R^2 value.

```{r}
tune_RF_model <- rand_forest(mtry = tune(), min_n = tune()) |>
  set_engine("randomForest") |>
  set_mode("regression")
    
tune_RF_model
```

```{r}
RF_tune_wflow <- workflows::workflow() |>
  workflows::add_recipe(RF_rec) |>
  workflows::add_model(tune_RF_model)

RF_tune_wflow
```

```{r}
n_cores <- parallel::detectCores()
n_cores
```

```{r}
doParallel::registerDoParallel(cores = n_cores)

set.seed(123)
tune_RF_results <- tune_grid(object = RF_tune_wflow, resamples = vfold_pm, grid = 20)
tune_RF_results
```

```{r}
tune_RF_results |>
  collect_metrics()
```

```{r}
show_best(tune_RF_results, metric = "rmse", n = 1)
```

```{r}
tuned_RF_values <- select_best(tune_RF_results,  metric = "rmse")
tuned_RF_values
```

```{r}
# specify best combination from tune in workflow
RF_tuned_wflow <-RF_tune_wflow |>
  tune::finalize_workflow(tuned_RF_values)

# fit model with those parameters on train AND test
overallfit <- RF_wflow |>
  tune::last_fit(pm_split)

collect_metrics(overallfit)
```

We now see a slightly improved R^2 value on the test data.

```{r}
test_predictions <- collect_predictions(overallfit)
test_predictions
```

In using a random forest to find the best model for predicting air quality from our data:
- Multiple decision trees are created
- Each tree is built using a random subset of the training data with replacement
- The randomness helps to keep the algorithm from overfitting the data
- The mean of the predictions from each of the trees is used in the final output


```{r}
#split
set.seed(1234)
pm_split <- rsample::initial_split(data = pm, prop = 2/3)

#label the sections
train_pm <- rsample::training(pm_split)
test_pm <- rsample::testing(pm_split)

#recipe
RF_rec <- recipe(train_pm) |>
    update_role(everything(), new_role = "predictor")|>
    update_role(value, new_role = "outcome")|>
    update_role(id, new_role = "id variable") |>
    update_role("fips", new_role = "county id") |>
    step_novel("state") |>
    step_string2factor("state", "county", "city") |>
    step_rm("county") |>
    step_rm("zcta") |>
    step_corr(all_numeric())|>
    step_nzv(all_numeric())

# install.packages("randomForest")
RF_PM_model <- parsnip::rand_forest(mtry = 10, min_n = 3) |> 
  set_engine("randomForest") |>
  set_mode("regression")

RF_PM_model

#Workflow code from lecture
RF_wflow <- workflows::workflow() |>
  workflows::add_recipe(RF_rec) |>
  workflows::add_model(RF_PM_model)

RF_wflow

# Fitting the data
RF_wflow_fit <- parsnip::fit(RF_wflow, data = train_pm)

RF_wflow_fit

# Look at feature importance
RF_wflow_fit |> 
  extract_fit_parsnip() |> 
  vip::vip(num_features = 10)
```

## Results & Discussion

## Conclusion
